spring:
  application:
    name: data-server
  cloud:
    stream:
      instance-count: 1 #应用程序部署的实例数量
      instance-index: 0 #应用程序实例的索引
      kafka:
        binder:
          brokers: 192.100.1.112:9092
          zk-nodes: 192.100.1.112:2181
          min-partition-count: 1
          auto-create-topics: true  #默认为true，绑定器会自动创建新主题
          auto-add-partitions: true #默认为false，绑定器将在需要的时候自动创建新的分区
      bindings:
        input:
          destination: input
#          content-type: application/json
        output:
          destination: output  #这一个配置也可以不用写，默认就是输出通道的名字output
#          group: log-client #消费组，保证同一消费组中的消息只会有一个消费者实例接收和处理
          consumer:
            concurrency: 1      #输入通道消费组的并发数
            partitioned: false  #来自消息生产者的数据是否采用了分区
            autoCommitOffset: true

  datasource:
    url: jdbc:mysql://192.100.1.111:3306/dljyxt?serverTimezone=GMT
    username: root
    password: 123456
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
  data:
    elasticsearch:
      cluster-nodes: 127.0.0.1:9300
#      cluster-nodes: 127.0.0.1:9300, 192.100.1.60:9300, 192.100.1.16:9300, 192.100.1.17:9300
#      cluster-nodes: 192.100.1.16:9300
      repositories:
        enabled: true


eureka:
  instance:
    hostname: 192.100.1.231
#    hostname: 192.100.1.111
  client:
    service-url:
      defaultZone: http://192.100.1.111:8761/eureka/
server:
  port: 9010


mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.kd.dataserver.domain

