#应用名
spring.application.name=data-server

#端口号
server.port=9011

#本机地址和注册地址
eureka.instance.hostname=192.100.1.111
eureka.client.service-url.defaultZone=http://192.100.1.111:8761/eureka/, http://192.100.1.112:8762/eureka/

#消息队列的配置
spring.cloud.stream.instance-count=2
spring.cloud.stream.instance-index=1
spring.cloud.stream.kafka.binder.brokers=192.100.1.112:9092
spring.cloud.stream.kafka.binder.zk-nodes=192.100.1.112:2181
spring.cloud.stream.kafka.binder.min-partition-count=1
spring.cloud.stream.bindings.input.destination=Log
#消费组不同，对消息的消费情况也不同；如果把消费组改变了与之前不同的名字，那么将会消费之前发到kafka队列中的所有消息
#所以这里我有一个问题就是：是不是发到消息队列的消息会持久化到磁盘上，即使被一个消费组消费了也不会销毁？
spring.cloud.stream.bindings.input.group=data-server
#输入通道消费者的并发数，默认值是1
#spring.cloud.stream.bindings.input.consumer.concurrency=1
#来自消息生产者的数据是否采用了分区，默认值是false
#spring.cloud.stream.bindings.input.consumer.partitioned=false
#设置消费失败后最大重试次数，默认值是3
spring.cloud.stream.bindings.input.consumer.max-attempts=1
#重试消息处理的初始间隔时间，默认值是1000
#spring.cloud.stream.bindings.input.consumer.back-off-initial-interval=1000
#重试消息处理的最大间隔时间，默认值是10000
#spring.cloud.stream.bindings.input.consumer.back-off-max-interval=10000
#重试消息处理的时间间隔的递增乘数，默认值是2.0
#spring.cloud.stream.bindings.input.consumer.back-off-multiplier=2.0
spring.cloud.stream.bindings.output.destination=output


#MySQL数据库的配置
spring.datasource.url=jdbc:mysql://192.100.1.111:3306/dljyxt?serverTimezone=GMT
spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
mybatis.mapper-locations=classpath:mapper/*.xml
#mybatis.type-aliases-package=com.kd.dataserver.domain

#ElastricSearch的配置
#spring.data.elasticsearch.cluster-nodes=192.100.1.60:9300, 192.100.1.16:9300, 192.100.1.17:9300
#spring.data.elasticsearch.cluster-name=my-ela
#spring.data.elasticsearch.repositories.enabled=false
